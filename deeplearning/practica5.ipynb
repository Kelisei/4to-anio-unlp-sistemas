{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "91b031bd",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "La base de datos **MNIST** contiene imágenes de 28×28, en escala de grises, de números escritos a mano.  \n",
    "Está conformada por **60.000 ejemplos de entrenamiento** y **10.000 ejemplos de prueba**.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Para cargar las imágenes utilice:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "```\n",
    "\n",
    "Puede visualizar una imagen utilizando:\n",
    "\n",
    "```py\n",
    "nImg = 0  # nro. de imagen a visualizar\n",
    "plt.imshow(X_train[0, :, :], cmap='gray')\n",
    "```\n",
    "## a)\n",
    "\n",
    "Con el conjunto de 60.000 imágenes, entrene una red neuronal convolucional (CNN) para predecir el dígito presente en la imagen.\n",
    "Recuerde normalizar los valores de cada imagen.\n",
    "Salve el modelo para recuperarlo después.\n",
    "\n",
    "## b)\n",
    "\n",
    "Levante el modelo guardado en el punto anterior y utilice la clase DrawPanel del módulo utils.images \n",
    "de la carpeta fuentes para generar un dibujo escrito a mano de un dígito y predecir la clase a la que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d113d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de imágenes de entrenamiento: 60000\n",
      "Cantidad de imágenes de prueba: 10000\n",
      "Forma de una imagen: (28, 28)\n",
      "Cantidad de clases objetivo: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "# Cargar y normalizar el conjunto de datos MNIST\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "Y_train= to_categorical(np.array(Y_train))\n",
    "Y_test = to_categorical(np.array(Y_test))\n",
    "IMG_SHAPE = X_train[0].shape\n",
    "TARGET_CNT= len(Y_train[0])\n",
    "\n",
    "print(\"Cantidad de imágenes de entrenamiento:\", len(X_train))\n",
    "print(\"Cantidad de imágenes de prueba:\", len(X_test))\n",
    "print(\"Forma de una imagen:\", IMG_SHAPE)\n",
    "print(\"Cantidad de clases objetivo:\", TARGET_CNT)\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test  = X_test  / 255\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e29a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.3368 - val_accuracy: 0.9759 - val_loss: 0.0806\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9659 - loss: 0.1148 - val_accuracy: 0.9843 - val_loss: 0.0567\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0837 - val_accuracy: 0.9862 - val_loss: 0.0495\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0713 - val_accuracy: 0.9865 - val_loss: 0.0486\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0584 - val_accuracy: 0.9881 - val_loss: 0.0409\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0520 - val_accuracy: 0.9891 - val_loss: 0.0397\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0449 - val_accuracy: 0.9893 - val_loss: 0.0384\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0427 - val_accuracy: 0.9893 - val_loss: 0.0400\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0352 - val_accuracy: 0.9884 - val_loss: 0.0431\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0330 - val_accuracy: 0.9903 - val_loss: 0.0376\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9914 - loss: 0.0281\n",
      "Precisión en el conjunto de prueba: 0.9914000034332275\n"
     ]
    }
   ],
   "source": [
    "# Entrentar red convulucional\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))) # Usamos esto porque las imágenes son en escala de grises\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Reducimos la dimensionalidad para disminuir el costo computacional\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu')) # Segunda capa convolucional para extraer características más complejas\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))    # Otra capa de pooling para seguir reduciendo la dimensionalidad\n",
    "model.add(Flatten()) # Aplanamos las matrices 2D a un vector 1D para conectarlo a la capa densa\n",
    "model.add(Dense(128, activation='relu')) # Capa densa con 128 neuronas y función de activación ReLU para introducir no linealidad\n",
    "model.add(Dropout(0.5)) # Capa de dropout para prevenir el sobreajuste\n",
    "model.add(Dense(TARGET_CNT, activation='softmax')) # Capa de salida con función de activación softmax para clasificación multiclase\n",
    "\n",
    "# Terminar antes si la precisión de validación no mejora en 3 épocas consecutivas\n",
    "\n",
    "cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=[cb])\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Precisión en el conjunto de prueba:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9aea1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "El dígito predicho es: 8\n"
     ]
    }
   ],
   "source": [
    "# Levante el modelo guardado en el punto anterior y utilice la clase DrawPanel del módulo utils.images \n",
    "# de la carpeta fuentes para generar un dibujo escrito a mano de un dígito y predecir la clase a la que pertenece.\n",
    "\n",
    "import utils as img_utils\n",
    "drawn_image = img_utils.DrawPanel(width=200, height=200)\n",
    "drawn_image.show()\n",
    "# Obtener la imagen dibujada, preprocesarla y hacer la predicción\n",
    "image = drawn_image.get_image()\n",
    "image = image.resize((28, 28)).convert('L')  # Redimensionar y convertir a escala de grises\n",
    "image_array = np.array(image) / 255.0  # Normalizar\n",
    "image_array = image_array.reshape(1, 28, 28, 1)  # Ajustar la forma para el modelo\n",
    "prediction = model.predict(image_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(\"El dígito predicho es:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
